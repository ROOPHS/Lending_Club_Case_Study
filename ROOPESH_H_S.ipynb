{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1868ea3",
   "metadata": {},
   "source": [
    "   #                                  LENDING CASE-STUDY\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb933b06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b6990b0",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries And Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26c9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import regex as re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8823bedd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\loan.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Importing and loading Dataset.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mloan.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\loan.csv'"
     ]
    }
   ],
   "source": [
    "#Importing and loading Dataset.\n",
    "df = pd.read_csv(\".\\loan.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e477cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking shape of the data.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking percentage of null values in all the columns.\n",
    "100*df.isnull().mean()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5796671",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a619698",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43763c0",
   "metadata": {},
   "source": [
    "### Data cleaning is an important part of the data preparation process. By cleaning your data, you can ensure that your data is accurate, consistent, and complete. This will help you to get more reliable results from your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132e0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dropping Unwanted Columns.\n",
    "df = df.drop(df.iloc[:,np.arange(47,105)], axis=1)\n",
    "df = df.drop(df.iloc[:,np.arange(48,53)], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe73946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking shape of the data after removing unwanted columns.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking percentage of null values in all the columns.\n",
    "100*df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94215ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing columns with more than 30% of null values.\n",
    "df = df.drop(columns = [\"desc\", \"mths_since_last_delinq\", \"mths_since_last_record\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing some columns like ...\n",
    "#1. emp_title column is user given and irrelevent to the analysis.\n",
    "#2. pymnt_plan column is having only 1 common value \"n\".\n",
    "#3. title column is not required for analysis.\n",
    "#4. initial_list_status column is not required for analysis.\n",
    "#5. url column and Id column have relevant data so removing url column.\n",
    "df = df.drop(columns = [\"emp_title\", \"pymnt_plan\",\"title\", \"initial_list_status\",\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of null values After removing all the irrelavant and more than 30% null values columns.\n",
    "100*df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the dataset after cleaning some columns.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted data's attached to emp_length values.\n",
    "df.emp_length = df.emp_length.str.replace(' years', '')\n",
    "df.emp_length = df.emp_length.str.replace(' year', '')\n",
    "df.emp_length = df.emp_length.str.replace('< ', '')\n",
    "df.emp_length = df.emp_length.str.replace('+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f681dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted data's attached to int_rate values.\n",
    "df.int_rate = df.int_rate.str.replace('%', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted data's attached to revol_util values.\n",
    "df.revol_util = df.revol_util.str.replace('%', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted data's attached to zip_code values.\n",
    "df.zip_code = df.zip_code.str.replace('xx', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To dispaly dataset after removing all the unncessary things and columns.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c143979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.value_counts of home_ownership.\n",
    "df.home_ownership.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing 'NONE' datas, it is unnecessary. \n",
    "df = df[df.home_ownership!=\"NONE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb88737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After removing 'NONE' data from home_ownership rows.\n",
    "df.home_ownership.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28100e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing null values from all the necessary rows.\n",
    "df = df[~df[\"revol_util\"].isnull()]\n",
    "df = df[~df[\"last_pymnt_d\"].isnull()]\n",
    "df = df[~df[\"pub_rec_bankruptcies\"].isnull()]\n",
    "df = df[~df[\"emp_length\"].isnull()]\n",
    "100*df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ab187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting emp_length to int.\n",
    "df.emp_length = df.emp_length.astype(\"int\")\n",
    "df.emp_length.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a20331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting int_rate, revol_util to float.\n",
    "df.loc[:,['int_rate','revol_util']] =df.loc[:,['int_rate','revol_util']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1105cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the Dtype of each column.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a145b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying dataset after doing all the necessary cleaning and conversion.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting string calender 'issue_d' to int. \n",
    "df['issue_d']=df['issue_d'].apply(lambda x: datetime.strptime(x, '%b-%y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After converting 'issue_d' row looks like.\n",
    "df.issue_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding extra columns like Year and Month from issue_d column.\n",
    "df['Year'] = df['issue_d'].apply(lambda x: x.year)\n",
    "df['Month'] = df['issue_d'].apply(lambda x: x.month)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62433abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amputing mean value of emp_length to Null/nan values.\n",
    "df.emp_length = df['emp_length'].fillna(int(df['emp_length'].mean()))\n",
    "df.emp_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fe750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After cleaning Dataset looks like...\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cefee0b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca57d682",
   "metadata": {},
   "source": [
    "## 3.  Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ce54d",
   "metadata": {},
   "source": [
    "## Univariate Analysis.\n",
    "###        Univariate analysis is a statistical procedure that involves examining a single variable at a time. It is a useful tool for understanding the basic characteristics of a dataset, such as the mean, median, mode, and standard deviation. Univariate analysis can also be used to identify outliers and trends in the data. Method used perform univariate analysis is Histogram and Barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a84541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coping df to df1 to continue operations on df1.\n",
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicant selecting term duration.\n",
    "fig = px.histogram(df1, x=\"term\", width=500, color_discrete_sequence=['#377EB8'])\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicant selecting term duration\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629331b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicants Grade based on LC.\n",
    "fig = px.histogram(df1, x=\"grade\", width=700, color_discrete_sequence=['#FF7F00']).update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Grade based on LC\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicants sub-Grade based on LC.\n",
    "fig = px.histogram(df1, x=\"sub_grade\", width=700, color_discrete_sequence=['#E6AB02']).update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants sub-Grade based on LC\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicants Home Ownership details during Registration.\n",
    "fig = px.histogram(df1, x=\"home_ownership\", width=500, color_discrete_sequence=['#ff0040']).update_xaxes(categoryorder=\"total descending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Home Ownership details during Registration\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicants Verification Status.\n",
    "fig = px.histogram(df1, x=\"verification_status\", width=500, color_discrete_sequence=['#80ff00']).update_xaxes(categoryorder=\"total descending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Verification Status\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebef269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicants Current Loan Status.\n",
    "fig = px.histogram(df1, x=\"loan_status\", width=500, color_discrete_sequence=['#DC3912']).update_xaxes(categoryorder=\"total descending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Current Loan Status\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Work Experience of Applicants.\n",
    "fig = px.histogram(df1, x=\"emp_length\", width=700, color_discrete_sequence=['#FECB52']).update_xaxes(categoryorder=\"total descending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Work Experience of Applicants\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Applicants Loan amount.\n",
    "fig = px.box(df1, y=\"loan_amnt\", width=500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Loan amount\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Loan Interest Rate of Applicants.\n",
    "fig = px.histogram(df1, x=\"int_rate\", width=700, color_discrete_sequence=['#D626FF'], nbins=10).update_xaxes(categoryorder=\"total descending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Loan Interest Rate of Applicants\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Loan Purpose of Applicant.\n",
    "fig = px.histogram(df1, x=\"purpose\", width=800).update_xaxes(categoryorder=\"total descending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Loan Purpose of Applicant\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Total Payment received from Applicants.\n",
    "fig = px.box(df1, y=\"total_pymnt\", width=500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Total Payment received from Applicants\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4879e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Annual Income of Applicants.\n",
    "fig = px.box(df1, y=\"annual_inc\", width=500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Annual Income of Applicants\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Interest rate across the loans.\n",
    "fig = px.box(df1, y=\"int_rate\", width=500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Interest rate across the loans\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e511ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Interquantile range for column int_rate.\n",
    "Q1 = df1['int_rate'].quantile(0.25)\n",
    "Q3 = df1['int_rate'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to find upper and lower fence from int_rate column.\n",
    "df1 = df1[~(df['int_rate'] > (Q3 + 1.5 * IQR)) ]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a univariate graph to analyse the Interest rate across the loans after removing outliers.\n",
    "fig = px.box(df1, y=\"int_rate\", width=500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Interest rate across the loans\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9887f455",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c22d2bf1",
   "metadata": {},
   "source": [
    "## Segmented-Univariate Analyses \n",
    "### Segmented univariate analysis is a data analysis technique that involves dividing a dataset into segments based on a categorical variable and then performing univariate analysis on each segment. This technique can be used to identify patterns and relationships within a dataset that would not be visible if the data were analyzed as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Segmented-univariate graph to analyse the Interest rate vs Grade.\n",
    "fig = px.box(df1, y=\"int_rate\", x=\"grade\").update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text':\"Interest rate vs Grade\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Segmented-univariate graph to analyse the Applicants Loan Amount for Term.\n",
    "fig = px.box(df1, y=\"loan_amnt\", x=\"term\").update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Loan Amount for Term\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef2306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting a Segmented-univariate graph to analyse the Applicants Loan Amount for home_ownership.\n",
    "fig = px.box(df1, y=\"loan_amnt\", x=\"home_ownership\").update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Loan Amount for home_ownership\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Segmented-univariate graph to analyse the Applicants Loan Amount for purpose.\n",
    "fig = px.box(df1, y=\"loan_amnt\", x=\"purpose\").update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants Loan Amount for purpose\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Segmented-univariate graph to analyse the Applicants verification_status for loan_amnt.\n",
    "fig = px.box(df1, y=\"loan_amnt\", x=\"verification_status\").update_xaxes(categoryorder=\"category ascending\")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Applicants verification_status for loan_amnt\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce72a2f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96cb52c6",
   "metadata": {},
   "source": [
    "## Bivariate Analysis\n",
    "### Bivariate analysis is a statistical method used to examine the relationship between two variables. It involves collecting data on two variables and then analyzing the data to determine whether there is a statistical relationship between them. It can be use Identify trends and patterns in data,Test hypotheses about relationships between variables,Make predictions about future values of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c79357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis on categorical data.\n",
    "#Risk Factor : We can see that clearly that the interest rate for the Verified users are preety high then of Not verified. and even for fully paid the gradually intrest goes down This is one of the risk factor.\n",
    "df1 = pd.pivot_table(data=df1,index='loan_status',values='int_rate',columns='verification_status')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da315cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis on categorical data.\n",
    "#We can see that, for purpose small_business\n",
    "#debt_consolidation : 34492725\n",
    "#credit_card : 6331175\n",
    "#small_business : 6127100\n",
    "#We have maximum charged of...\n",
    "df1 = pd.pivot_table(data=df[df['loan_status']=='Charged Off'],index='purpose',values='funded_amnt', aggfunc='sum')\n",
    "df1.sort_values(by='funded_amnt',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis on categorical data.\n",
    "#Risk Factor\n",
    "#1.MORTGAGE 13737.677508\n",
    "#2.OTHER 13326.388889\n",
    "#These two have high percentage of Charged off part\n",
    "df2 = pd.pivot_table(data=df[df['loan_status']=='Charged Off'],index='home_ownership',values='funded_amnt')\n",
    "df2.sort_values(by='funded_amnt',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis on categorical data.\n",
    "#Plotting a Bivariate graph to analyse the Applicants int_rate for loan_status.\n",
    "crosstab = pd.crosstab(df['addr_state'],df['loan_status'])\n",
    "px.bar(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Bivariate graph on categorical data to analyse the Applicants loan_status for annual_inc.\n",
    "#Risk Factor:\n",
    "#The current annual increment will also define the Charged Off part, for current ongoing loan the increment value is high so there is chance that it would be paid correctly For the Charged off increment value is little low\n",
    "df1 = pd.pivot_table(df,index='loan_status',values='annual_inc',aggfunc='median')\n",
    "px.bar(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa105cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Bivariate graph on categorical data to analyse the Applicants purpose for funded_amnt_inv.\n",
    "fig = px.histogram(df, y =\"funded_amnt_inv\", x=\"purpose\", width=700, color_discrete_sequence=['#FF7F00'])\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Number of Apllicants selecting term\\n\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4540d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coping df to df2 to continue operations on df2.\n",
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Correlation between all Numerical Columns\n",
    "df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db794bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Bivariate correlation graph on categorical data to analyse the Applicants purpose for term.\n",
    "crosstab = pd.crosstab(df2['purpose'], df2['term'])\n",
    "fig = px.bar(crosstab, color='term')\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Purpose Vs Term\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52870bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Bivariate correlation graph on categorical data to analyse the Applicants purpose for loan_status.\n",
    "crosstab1 = pd.crosstab(df2['purpose'], df2['loan_status'])\n",
    "fig = px.bar(crosstab1, color='loan_status')\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Purpose Vs Loan Status\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b98f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Bivariate correlation graph on categorical data to analyse the Applicants sub_grade for purpose.\n",
    "crosstab2 = pd.crosstab(df2['sub_grade'], df2['purpose'])\n",
    "fig = px.bar(crosstab2, color='purpose')\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Sub Grade Vs Purpose\\n\",\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Another Dataframe with selected Columns from Df2 Dataframe to create Coorelation Matrix Heatmap on numerical data.\n",
    "heatMap = df2[[\"loan_amnt\", \"funded_amnt\",\"installment\", \"total_pymnt\",\"total_pymnt_inv\", \"total_rec_int\",\"collection_recovery_fee\", \"recoveries\", \"installment\",\"dti\"]]\n",
    "heatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffc11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#considered +ve, -ve and near to 0 vaalues.\n",
    "correlation_matrix = heatMap.corr(method = \"spearman\")\n",
    "\n",
    "# Create a heatmap of the correlation matrix on numerical data.\n",
    "fig = px.imshow(correlation_matrix, width=1000, height=800, text_auto=True)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Coorelation Heatmap with different Numerical Columns\\n\",\n",
    "        'y':0.96,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e794581",
   "metadata": {},
   "source": [
    "## Derived Metrics\n",
    "### A derived metric is a metric that is calculated from one or more existing metrics. Derived metrics are used to provide additional insights into data that cannot be obtained from the existing metrics alone. They are often used to create more complex metrics, such as ratios, percentages, and averages.\n",
    "### By using derived metrics, you can uncover hidden patterns, make data more actionable, and save time and effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Derieved graph on data to analyse the Loan Status in every Year.\n",
    "DM = pd.crosstab(df2['Year'], df2['loan_status'])\n",
    "fig = px.bar(DM, color='loan_status')\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Loan Status in every Year\\n\",\n",
    "        'y':0.96,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Derieved graph on data to analyse the loan_amount Done by Applicants in Every Year.\n",
    "df2.groupby('Year')['loan_amnt'].mean().plot.line()\n",
    "plt.title(\"loan_amount Done by Applicants in Every Year\\n\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"loan_amnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27205604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a Derieved graph on data to analyse the Total payment Done by Applicants for Every Year.\n",
    "df2.groupby('Year')['total_pymnt'].mean().plot.line()\n",
    "plt.title(\"Total payment Done by Applicants for Every Year\\n\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Payment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
